% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/base_identify.R
\name{precheck_identification}
\alias{precheck_identification}
\title{Weight-based numerical identifiability diagnostics}
\usage{
precheck_identification(
  X,
  delta = 0.1,
  Xdensity_learners = NULL,
  Xbinary_learners = NULL,
  verbose = FALSE,
  scale_continuous = TRUE,
  threshold = 10,
  ...
)
}
\arguments{
\item{X}{data frame of predictors}

\item{delta}{change in each column of predictors in call to varimp corresponding to stochastic intervention}

\item{Xdensity_learners}{list of sl3 learners used to estimate the density of continuous predictors, conditional on all other predictors in X}

\item{Xbinary_learners}{list of sl3 learners used to estimate the probability mass of continuous predictors, conditional on all other predictors in X}

\item{verbose}{(logical) print extra information}

\item{scale_continuous}{(logical) scale continuous variables in X to have standard deviation of 0.5}

\item{threshold}{(numeric, default=10) threshold for high weights}

\item{...}{passed to sl3::make_sl3_Task (e.g. weights)}
}
\description{
This function allows one to check, prior to performing inference with \code{vibr::varimp}, whether implied stochastic interventions may be subject to sparsity. Primarily, this approach is based off of estimates of generalized-propensity score weights, where extreme values can suggest highly influential observations due to sparsity.
}
\details{
Generally, the identifiability will not be obtained if there are some values of the implied stochastic intervention that have a probability mass/density = 0. This will often not occur in fitted models due to some form of local parametric smoothing, so instead looking for extreme values inverse mass/density based weights can help to suggest where the implied stochastic intervention is extrapolating beyond the observed predictor data.
}
\examples{
\dontrun{
data(metals, package="qgcomp")
XYlist = list(X=metals[,1:23], Y=metals$y)
Xbinary_learners = .default_binary_learners()
Xdensity_learners = .default_density_learners(n_bins=c(5, 20))
set.seed(12321)
# check for intervention = 0.02 standard deviations (scale_continuous=TRUE
# will scale continuous predictors to have sd=0.5)
ident <- precheck_identification(X=XYlist$X[,1:23], delta=0.01,
       Xdensity_learners=Xdensity_learners[c(1,2,3)],
       Xbinary_learners=Xbinary_learners, threshold=10,
       scale_continuous = TRUE)
ident
# some extreme weights suggest using a smaller delta. This can be done
# by manually scaling variables with extreme weights to have a larger standard deviation
# (so that delta would imply a smaller effect size), or one can simply set
# delta to a smaller value.
}



}
